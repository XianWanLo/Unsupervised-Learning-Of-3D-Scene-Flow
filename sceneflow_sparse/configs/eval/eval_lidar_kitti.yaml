method: 
  backbone: 'ME' # Type of backbone network [ME]
  flow: True # Use scene-flow head
  ego_motion: True # Use ego-motion head
  semantic: True # Use background segmentation head
  clustering: True # Use foreground clustering head

misc:
  run_mode: test # Mode to run the network in

data:
  dataset: LidarKITTI_ME # Name of the dataset [StereoKITTI_ME, FlyingThings3D_ME, SemanticKITTI_ME, LidarKITTI_ME, WaymoOpen_ME]
  root: ./../../dataset/lidar_kitti # Path to the data
  input_features: absolute_coords # Input features assigned to each sparse voxel
  n_classes: 2 # Number of classes for the background segmentation head
  remove_ground: True # Remove ground by simple thresholding of the height coordinate
  augment_data: False # Augment the data by random rotation and translation

network:
  normalize_features: True
  norm_type: IN # Type of normalization layer IN = instance, BN = batch normalization, False = no normalization
  in_kernel_size: 7 # Size of the initial convolutional kernel 
  feature_dim: 64
  ego_motion_points: 1024 # Number of points that are randomly sampled for the ego motion estimation
  add_slack: True # Add slack row and column in the Sinkhorn iteration module
  sinkhorn_iter: 3 # Number of Sinkhorn iterations in the ego motion module
  use_pretrained: True # Flag for training
  cluster_metric: euclidean # Distance metric used to compute the cluster assignments 0 = Euclidean
  min_p_cluster: 30 # Min number of points in a cluster 
  min_samples_dbscan: 5 # Min number of points in the neighborhood DBSCAN
  eps_dbscan: 0.75 # Eps value in DBSCAN for the Euclidean distance
  pretrained_path: logs/logs_SemanticKITTI_ME/full_scratch_all_loss/model_best.pt # Path to the pretrained model
  
test:
  batch_size: 1 # Test batch size
  num_workers: 1 # Num of workers to use for the test data set
  postprocess_ego: True  # Apply postprocessing (optimization of the ego-motion)
  postprocess_clusters: True # Apply postprocessing (optimization of the motion across the clusters)
  results_dir: ./eval_results/lidar_kitti/

loss: 
  background_loss: False # Compute background loss
  flow_loss: False # Compute flow loss
  ego_loss: False # Compute ego-motion loss
  foreground_loss: False # Compute foreground loss

metrics:
  flow: True # Compute evaluation metrics for flow estimation (EPE3D, Acc3DS, Acc3DR, Outliers)
  ego_motion: True # Compute evaluation metrics for ego-motion estimation (RRE, RTE)
  semantic: False # Compute evaluation metrics for background segmentation (Precision, Recall)


batch_size: 1
beta: 0.999
data: ./../../dataset/kitti_256/
decay_rate: 0.7
decay_step: 200000

depth_name: DispResNet
epochs: 200
evaluate: False
flownet_name: HALFlow
flag_big_radius: 1

kitti_rm_height: 540
kitti_rm_width: 960

kitti_height: 375
kitti_width: 1242

index_num: 8192
is_training: True

kernel_shape: 1
layers: 1

load_weights_folder: ./pretrained_weight/sc_depth/

loss_weight_dc: 0.1
loss_weight_ods: 0.1
chamfer_loss_weight: 1
curvature_loss_weight: 0.3
smoothness_loss_weight: 0.1
photometric_loss_weight: 0.1
lr: 0.001
momentum: 0.9
multi_gpu: False

name: scene_color
num_points: 2048
pose_name: PoseResNet
pretrained_disp: ./pretrained_weight/SC_depth/dispnet_model_best.pth.tar
pretrained_posenet: ./pretrained_weight/SC_depth/exp_pose_model_best.pth.tar

resnet_layers: 50
resume: True
resume_name: ./../checkpoints_final/sceneflow_color/scene_model.newest.t7
save_path: ./../checkpoints_final/
seed: 0
sequence_length: 3
test_batch_size: 1
test_data_path: ./../../dataset/kitti_rm_ground
test_period: 1
weight_decay: 0
workers: 2
